{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for easy reference and modification\n",
    "GROUPBY_COL = 'unique_id'\n",
    "\n",
    "DATETIME_COL = 'datetime'\n",
    "\n",
    "TARGET_COL = 'vehicle_type'\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'vehicle_speed',\n",
    "    'vehicle_angle_sine', 'vehicle_angle_cosine',\n",
    "    'vehicle_x', 'vehicle_y', 'vehicle_z'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "\n",
    "# PyTorch and related imports\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions and Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split_custom(df, test_size=0.2, val_size=0.1, min_per_class=1):\n",
    "    \"\"\"\n",
    "    Splits data into training, validation, and test sets.\n",
    "    Ensures that a vehicle_id only appears in one of the datasets.\n",
    "    Ensures that all possible classes are represented in each set.\n",
    "    In the event where a class has not enough vehicle_ids for each set to have at least one vehicle_id,\n",
    "    prioritise the train set to represent all possible classes.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # Seed for reproducibility\n",
    "\n",
    "    # Get unique IDs and classes\n",
    "    unique_ids = df[GROUPBY_COL].unique()\n",
    "    classes = df[TARGET_COL].unique()\n",
    "\n",
    "    # Initialize lists to store IDs for each dataset\n",
    "    train_ids, val_ids, test_ids = [], [], []\n",
    "\n",
    "    for cls in classes:\n",
    "        ids_for_class = df[df[TARGET_COL] == cls][GROUPBY_COL].unique()\n",
    "        np.random.shuffle(ids_for_class)\n",
    "\n",
    "        # Allocate IDs to train, val, and test sets\n",
    "        class_count = len(ids_for_class)\n",
    "        train_end = min(min_per_class, class_count)\n",
    "        val_end = min(train_end + min_per_class, class_count)\n",
    "        test_end = min(val_end + min_per_class, class_count)\n",
    "\n",
    "        train_ids.extend(ids_for_class[:train_end])\n",
    "        val_ids.extend(ids_for_class[train_end:val_end])\n",
    "        test_ids.extend(ids_for_class[val_end:test_end])\n",
    "\n",
    "    # Shuffle remaining IDs after removing selected train IDs\n",
    "    reserved_ids = set(train_ids + val_ids + test_ids)\n",
    "    remaining_ids = list(set(unique_ids) - reserved_ids)\n",
    "    np.random.shuffle(remaining_ids)\n",
    "\n",
    "    # Calculate split sizes for remaining IDs\n",
    "    total_remaining = len(remaining_ids)\n",
    "    test_count = int(total_remaining * test_size)\n",
    "    val_count = int(total_remaining * val_size)\n",
    "\n",
    "    # Assign remaining vehicle IDs to test and validation sets\n",
    "    test_ids += remaining_ids[:test_count]\n",
    "    val_ids += remaining_ids[test_count:test_count + val_count]\n",
    "    train_ids += remaining_ids[test_count + val_count:]\n",
    "\n",
    "    # Create split DataFrames\n",
    "    train_df = df[df[GROUPBY_COL].isin(train_ids)]\n",
    "    val_df = df[df[GROUPBY_COL].isin(val_ids)]\n",
    "    test_df = df[df[GROUPBY_COL].isin(test_ids)]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def create_sequences(df):\n",
    "    sequences = []\n",
    "    for vehicle_id, group in df.groupby(GROUPBY_COL):\n",
    "        sorted_group = group.sort_values(by=[DATETIME_COL]).copy()\n",
    "        sequence_features = sorted_group[FEATURE_COLS].values\n",
    "        label = sorted_group.iloc[0][TARGET_COL]\n",
    "        sequences.append((sequence_features, label, vehicle_id))\n",
    "    return sequences\n",
    "\n",
    "class VehicleDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sequences = create_sequences(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label, vehicle_id = self.sequences[idx]\n",
    "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(label, dtype=torch.long), vehicle_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels, vehicle_ids = zip(*batch)\n",
    "\n",
    "    # Clone and detach the tensors in sequences before padding\n",
    "    padded_sequences = pad_sequence([seq.clone().detach() for seq in sequences], batch_first=True)\n",
    "\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "\n",
    "    return padded_sequences, labels_tensor, vehicle_ids, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## USING GENERATORS ########################\n",
    "def create_sequences_generator(df):\n",
    "    for vehicle_id, group in df.groupby(GROUPBY_COL):\n",
    "         # Ensure that data is sorted by  datetime\n",
    "        group[DATETIME_COL] = pd.to_datetime(group[DATETIME_COL])\n",
    "        group.sort_values(by=[DATETIME_COL], inplace=True)\n",
    "\n",
    "        sequence_features = group[FEATURE_COLS].values\n",
    "        label = group.iloc[0][TARGET_COL]\n",
    "        yield sequence_features, label, vehicle_id\n",
    "\n",
    "class VehicleIterableDataset(IterableDataset):\n",
    "    def __init__(self, df):\n",
    "        # IterableDataset stores the raw data and parameters needed to create the generator\n",
    "        self.df = df\n",
    "        self.groupby_col = GROUPBY_COL\n",
    "        self.feature_cols = FEATURE_COLS\n",
    "        self.target_col = TARGET_COL\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Re-initialises the generator each time it is called, as generators are exhausted after one complete iteration\n",
    "        return create_sequences_generator(self.df)\n",
    "\n",
    "def collate_fn_generator(batch):\n",
    "    # Separate features, labels, and vehicle IDs\n",
    "    sequences, labels, vehicle_ids = zip(*batch)\n",
    "\n",
    "    # Pad sequences to have the same length\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in sequences], batch_first=True)\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # Calculate lengths of sequences\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "\n",
    "    return padded_sequences, labels_tensor, vehicle_ids, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load resampled data into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1228962 entries, 0 to 1228961\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   unique_id             1228962 non-null  object        \n",
      " 1   datetime              1228962 non-null  datetime64[ns]\n",
      " 2   vehicle_id            1228962 non-null  object        \n",
      " 3   timestep_time         1228962 non-null  float64       \n",
      " 4   vehicle_type          1228962 non-null  object        \n",
      " 5   vehicle_speed         1228962 non-null  float64       \n",
      " 6   vehicle_x             1228962 non-null  float64       \n",
      " 7   vehicle_y             1228962 non-null  float64       \n",
      " 8   vehicle_z             1228962 non-null  float64       \n",
      " 9   vehicle_angle         1228962 non-null  float64       \n",
      " 10  vehicle_angle_sine    1228962 non-null  float64       \n",
      " 11  vehicle_angle_cosine  1228962 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), object(3)\n",
      "memory usage: 112.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('resampled_vehicle_data.csv')\n",
    "df[DATETIME_COL] = pd.to_datetime(df[DATETIME_COL])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Re-labelling classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this notebook on GitHub](https://github.com/pgrandinetti/standard-traffic-data/blob/main/knowledge/Urban_Traffic_Data_Statistical_Analysis.ipynb), we:\n",
    "\n",
    "- Fill in null values with `pedestrian`\n",
    "- Rename all vehicle types types that start with `passenger` as `car` as these instances are a subclass of car\n",
    "- Rename vehicle types suffixed with bicycle (`fastbicycle`, `avgbicycle`, `slowbicycle`) as `bicycle`\n",
    "- Rename `trailer` and `truck` as `lorry` as trailer is just a variation of truck\n",
    "- Rename `uber` and `taxi` as `hire` as they represent the same concept\n",
    "- Rename `army`, `authority`, `emergency` vehicles as `special`\n",
    "- Drop all vehicle types starting with `hw_` as these vehicles run on motorways and hence not suitable for urban traffic analysis\n",
    "- Drop rows containing `train` as they are not suitable for urban traffic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[TARGET_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename vehicle types\n",
    "df[TARGET_COL] = df[TARGET_COL].replace(regex={\n",
    "    '^passenger.*': 'car',\n",
    "    '.*bicycle$': 'bicycle',\n",
    "    '^(trailer|truck)$': 'lorry',\n",
    "    '^(uber|taxi)$': 'hire',\n",
    "    '^(army|authority|emergency)$': 'special'\n",
    "})\n",
    "\n",
    "# Drop rows where vehicle types start with 'hw_' or are 'train'\n",
    "df = df[~df[TARGET_COL].str.startswith('hw_')]\n",
    "df = df[df[TARGET_COL] != 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df[TARGET_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'unique_id' and 'datetime' to ensure the correct order\n",
    "df = df.sort_values(by=[GROUPBY_COL, DATETIME_COL]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[TARGET_COL] = df[TARGET_COL].apply(str)\n",
    "df[TARGET_COL] = le.fit_transform(df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'army',\n",
      " 1: 'authority',\n",
      " 2: 'avgbicycle',\n",
      " 3: 'bus',\n",
      " 4: 'coach',\n",
      " 5: 'delivery',\n",
      " 6: 'emergency',\n",
      " 7: 'fastbicycle',\n",
      " 8: 'hw_coach',\n",
      " 9: 'hw_delivery',\n",
      " 10: 'hw_motorcycle',\n",
      " 11: 'hw_passenger1',\n",
      " 12: 'hw_passenger2a',\n",
      " 13: 'hw_passenger2b',\n",
      " 14: 'hw_passenger3',\n",
      " 15: 'hw_passenger4',\n",
      " 16: 'hw_trailer',\n",
      " 17: 'hw_truck',\n",
      " 18: 'moped',\n",
      " 19: 'motorcycle',\n",
      " 20: 'passenger1',\n",
      " 21: 'passenger2a',\n",
      " 22: 'passenger2b',\n",
      " 23: 'passenger3',\n",
      " 24: 'passenger4',\n",
      " 25: 'slowbicycle',\n",
      " 26: 'taxi',\n",
      " 27: 'trailer',\n",
      " 28: 'train',\n",
      " 29: 'truck',\n",
      " 30: 'uber'}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "pprint.pprint(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train val test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6138 vehicle_ids and 1228962 rows in df.\n",
      "31 classes are represented in df.\n",
      "\n",
      "vehicle_ids\n",
      "vehicle_type\n",
      "19    1000\n",
      "22     596\n",
      "24     588\n",
      "21     583\n",
      "23     582\n",
      "20     573\n",
      "18     451\n",
      "5      317\n",
      "3      192\n",
      "2      177\n",
      "7      160\n",
      "25     128\n",
      "30     125\n",
      "6      119\n",
      "26     115\n",
      "1       70\n",
      "27      54\n",
      "12      34\n",
      "4       29\n",
      "16      26\n",
      "11      26\n",
      "9       26\n",
      "8       26\n",
      "29      25\n",
      "15      24\n",
      "13      24\n",
      "17      20\n",
      "14      18\n",
      "10      16\n",
      "28      12\n",
      "0        2\n",
      "Name: unique_id, dtype: int64\n",
      "\n",
      "num_rows\n",
      "vehicle_type\n",
      "19    210160\n",
      "22    156408\n",
      "23    153694\n",
      "20    147510\n",
      "24    145906\n",
      "21    140714\n",
      "18     91608\n",
      "3      39480\n",
      "5      36238\n",
      "2      14106\n",
      "6      12624\n",
      "25     12255\n",
      "7      11201\n",
      "27      8236\n",
      "1       8182\n",
      "30      7526\n",
      "26      6682\n",
      "28      5404\n",
      "29      2924\n",
      "4       2706\n",
      "12      1990\n",
      "8       1813\n",
      "16      1801\n",
      "11      1632\n",
      "13      1539\n",
      "9       1537\n",
      "15      1485\n",
      "17      1376\n",
      "14      1107\n",
      "10       991\n",
      "0        127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = train_val_test_split_custom(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect balance of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6138 vehicle_ids and 1228962 rows in df.\n",
      "31 classes are represented in df.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df[GROUPBY_COL].nunique()} vehicle_ids and {len(df)} rows in df.\")\n",
    "print(f\"{df[TARGET_COL].nunique()} classes are represented in df.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_ids\n",
      "vehicle_type\n",
      "19    1000\n",
      "22     596\n",
      "24     588\n",
      "21     583\n",
      "23     582\n",
      "20     573\n",
      "18     451\n",
      "5      317\n",
      "3      192\n",
      "2      177\n",
      "7      160\n",
      "25     128\n",
      "30     125\n",
      "6      119\n",
      "26     115\n",
      "1       70\n",
      "27      54\n",
      "12      34\n",
      "4       29\n",
      "16      26\n",
      "11      26\n",
      "9       26\n",
      "8       26\n",
      "29      25\n",
      "15      24\n",
      "13      24\n",
      "17      20\n",
      "14      18\n",
      "10      16\n",
      "28      12\n",
      "0        2\n",
      "Name: unique_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of unique_ids\n",
    "print('unique_ids')\n",
    "print(f\"{df.groupby(TARGET_COL)[GROUPBY_COL].nunique().sort_values(ascending=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows\n",
      "vehicle_type\n",
      "19    210160\n",
      "22    156408\n",
      "23    153694\n",
      "20    147510\n",
      "24    145906\n",
      "21    140714\n",
      "18     91608\n",
      "3      39480\n",
      "5      36238\n",
      "2      14106\n",
      "6      12624\n",
      "25     12255\n",
      "7      11201\n",
      "27      8236\n",
      "1       8182\n",
      "30      7526\n",
      "26      6682\n",
      "28      5404\n",
      "29      2924\n",
      "4       2706\n",
      "12      1990\n",
      "8       1813\n",
      "16      1801\n",
      "11      1632\n",
      "13      1539\n",
      "9       1537\n",
      "15      1485\n",
      "17      1376\n",
      "14      1107\n",
      "10       991\n",
      "0        127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of rows\n",
    "print('num_rows')\n",
    "print(f\"{df[TARGET_COL].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4264 vehicle_ids and 857233 rows in train_df.\n",
      "31 classes are represented in train_df.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {train_df[GROUPBY_COL].nunique()} vehicle_ids and {len(train_df)} rows in train_df.\")\n",
    "print(f\"{train_df[TARGET_COL].nunique()} classes are represented in train_df.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_ids\n",
      "vehicle_type\n",
      "19    685\n",
      "22    432\n",
      "24    416\n",
      "21    412\n",
      "20    411\n",
      "23    394\n",
      "18    305\n",
      "5     206\n",
      "3     138\n",
      "2     129\n",
      "7     113\n",
      "30     87\n",
      "25     84\n",
      "26     81\n",
      "6      78\n",
      "1      46\n",
      "27     34\n",
      "12     25\n",
      "4      22\n",
      "16     19\n",
      "29     19\n",
      "9      19\n",
      "13     17\n",
      "11     16\n",
      "8      16\n",
      "17     15\n",
      "15     14\n",
      "14     12\n",
      "10     11\n",
      "28      7\n",
      "0       1\n",
      "Name: unique_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of unique_ids\n",
    "print('unique_ids')\n",
    "print(f\"{train_df.groupby(TARGET_COL)[GROUPBY_COL].nunique().sort_values(ascending=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows\n",
      "vehicle_type\n",
      "19    143905\n",
      "22    116451\n",
      "24    106055\n",
      "20    105165\n",
      "23    102836\n",
      "21     99261\n",
      "18     58721\n",
      "3      28956\n",
      "5      23348\n",
      "2      10764\n",
      "25      8398\n",
      "6       8149\n",
      "7       7729\n",
      "30      5239\n",
      "1       5038\n",
      "26      4713\n",
      "27      4386\n",
      "28      3299\n",
      "4       2176\n",
      "29      2130\n",
      "12      1542\n",
      "16      1306\n",
      "9       1141\n",
      "8       1124\n",
      "13      1078\n",
      "17      1033\n",
      "11       995\n",
      "15       817\n",
      "14       776\n",
      "10       674\n",
      "0         28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of rows\n",
    "print('num_rows')\n",
    "print(f\"{train_df[TARGET_COL].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 635 vehicle_ids and 128574 rows in val_df.\n",
      "31 classes are represented in val_df.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {val_df[GROUPBY_COL].nunique()} vehicle_ids and {len(val_df)} rows in val_df.\")\n",
    "print(f\"{val_df[TARGET_COL].nunique()} classes are represented in val_df.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_ids\n",
      "vehicle_type\n",
      "19    114\n",
      "23     72\n",
      "21     63\n",
      "24     59\n",
      "20     51\n",
      "18     47\n",
      "22     47\n",
      "5      40\n",
      "7      19\n",
      "3      18\n",
      "2      16\n",
      "25     16\n",
      "6      15\n",
      "26     13\n",
      "27      6\n",
      "30      5\n",
      "15      4\n",
      "1       4\n",
      "11      3\n",
      "9       3\n",
      "8       3\n",
      "4       3\n",
      "17      2\n",
      "14      2\n",
      "13      2\n",
      "12      2\n",
      "28      2\n",
      "16      1\n",
      "10      1\n",
      "29      1\n",
      "0       1\n",
      "Name: unique_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of unique_ids\n",
    "print('unique_ids')\n",
    "print(f\"{val_df.groupby(TARGET_COL)[GROUPBY_COL].nunique().sort_values(ascending=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows\n",
      "vehicle_type\n",
      "19    26219\n",
      "23    20662\n",
      "21    14921\n",
      "24    14212\n",
      "20    13393\n",
      "18    10235\n",
      "22    10149\n",
      "5      4779\n",
      "3      3618\n",
      "6      1634\n",
      "7      1433\n",
      "25     1294\n",
      "2      1049\n",
      "26      836\n",
      "27      772\n",
      "28      560\n",
      "1       514\n",
      "4       382\n",
      "30      283\n",
      "15      267\n",
      "8       205\n",
      "9       201\n",
      "11      193\n",
      "17      138\n",
      "14      130\n",
      "13      120\n",
      "0        99\n",
      "12       89\n",
      "10       72\n",
      "16       69\n",
      "29       46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of rows\n",
    "print('num_rows')\n",
    "print(f\"{val_df[TARGET_COL].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1239 vehicle_ids and 243155 rows in test_df.\n",
      "30 classes are represented in test_df.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {test_df[GROUPBY_COL].nunique()} vehicle_ids and {len(test_df)} rows in test_df.\")\n",
    "print(f\"{test_df[TARGET_COL].nunique()} classes are represented in test_df.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_ids\n",
      "vehicle_type\n",
      "19    201\n",
      "22    117\n",
      "23    116\n",
      "24    113\n",
      "20    111\n",
      "21    108\n",
      "18     99\n",
      "5      71\n",
      "3      36\n",
      "30     33\n",
      "2      32\n",
      "7      28\n",
      "25     28\n",
      "6      26\n",
      "26     21\n",
      "1      20\n",
      "27     14\n",
      "12      7\n",
      "11      7\n",
      "8       7\n",
      "15      6\n",
      "16      6\n",
      "13      5\n",
      "29      5\n",
      "14      4\n",
      "10      4\n",
      "9       4\n",
      "4       4\n",
      "17      3\n",
      "28      3\n",
      "Name: unique_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of unique_ids\n",
    "print('unique_ids')\n",
    "print(f\"{test_df.groupby(TARGET_COL)[GROUPBY_COL].nunique().sort_values(ascending=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows\n",
      "vehicle_type\n",
      "19    40036\n",
      "23    30196\n",
      "22    29808\n",
      "20    28952\n",
      "21    26532\n",
      "24    25639\n",
      "18    22652\n",
      "5      8111\n",
      "3      6906\n",
      "27     3078\n",
      "6      2841\n",
      "1      2630\n",
      "25     2563\n",
      "2      2293\n",
      "7      2039\n",
      "30     2004\n",
      "28     1545\n",
      "26     1133\n",
      "29      748\n",
      "8       484\n",
      "11      444\n",
      "16      426\n",
      "15      401\n",
      "12      359\n",
      "13      341\n",
      "10      245\n",
      "17      205\n",
      "14      201\n",
      "9       195\n",
      "4       148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect balance of classes by number of rows\n",
    "print('num_rows')\n",
    "print(f\"{test_df[TARGET_COL].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duolux_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
